{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMpBVNUmlXbKd0PdfpD6xr/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WzUUYvD4FKsP","executionInfo":{"status":"ok","timestamp":1689836124220,"user_tz":-540,"elapsed":6666,"user":{"displayName":"Blessian White","userId":"18309571065164793243"}},"outputId":"b1694614-3d4d-4013-9a08-759eced6b050"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.3 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.3 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m1.1/1.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n"]}]},{"cell_type":"code","source":["import torch\n","import re\n","import sentencepiece as spm"],"metadata":{"id":"TWUUIlLdEwa-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Params"],"metadata":{"id":"W16rTJZwG0rv"}},{"cell_type":"code","source":["MAX_LENGTH = 40\n","START_TOKEN = [2]\n","END_TOKEN = [3]"],"metadata":{"id":"-FyEcEhIFfsG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\""],"metadata":{"id":"r4MGF9jKE0Rt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab_file = \"chatbot.model\"\n","vocab = spm.SentencePieceProcessor()\n","vocab.load(vocab_file)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"brpZcqFqER9-","executionInfo":{"status":"ok","timestamp":1689841008802,"user_tz":-540,"elapsed":11,"user":{"displayName":"Blessian White","userId":"18309571065164793243"}},"outputId":"c46eb8b8-027c-4baa-b428-7f8b662fbfe6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["corpus = \"all.txt\"\n","prefix = \"chatbot\"\n","# vocab_size = 16000\n","vocab_size = 30000\n","spm.SentencePieceTrainer.train(\n","    f\"--input={corpus} --model_prefix={prefix} --vocab_size={vocab_size + 7}\" +\n","    \" --model_type=bpe\" +\n","    \" --max_sentence_length=999999\" + # 문장 최대 길이\n","    \" --pad_id=0 --pad_piece=[PAD]\" + # pad (0)\n","    \" --unk_id=1 --unk_piece=[UNK]\" + # unknown (1)\n","    \" --bos_id=2 --bos_piece=[BOS]\" + # begin of sequence (2)\n","    \" --eos_id=3 --eos_piece=[EOS]\" + # end of sequence (3)\n","    \" --user_defined_symbols=[SEP],[CLS],[MASK]\") # 사용자 정의 토큰"],"metadata":{"id":"1zgHx-FjFI99"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"PB855FZCFx_k"}},{"cell_type":"code","source":["from torch.nn import Transformer\n","from torch import nn\n","import torch\n","import math\n","\n","class TFModel(nn.Module):\n","    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n","        super(TFModel, self).__init__()\n","        self.transformer = Transformer(ninp, nhead, dim_feedforward=nhid, num_encoder_layers=nlayers, num_decoder_layers=nlayers,dropout=dropout)\n","        self.pos_encoder = PositionalEncoding(ninp, dropout)\n","        self.encoder = nn.Embedding(ntoken, ninp)\n","\n","        self.pos_encoder_d = PositionalEncoding(ninp, dropout)\n","        self.encoder_d = nn.Embedding(ntoken, ninp)\n","\n","        self.ninp = ninp\n","        self.ntoken = ntoken\n","\n","        self.linear = nn.Linear(ninp, ntoken)\n","        self.init_weights()\n","\n","    def generate_square_subsequent_mask(self, sz):\n","        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n","        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","        return mask\n","\n","    def init_weights(self):\n","        initrange = 0.1\n","        self.encoder.weight.data.uniform_(-initrange, initrange)\n","\n","    def forward(self, src, tgt, srcmask, tgtmask, srcpadmask, tgtpadmask):\n","        src = self.encoder(src) * math.sqrt(self.ninp)\n","        src = self.pos_encoder(src)\n","\n","        tgt = self.encoder_d(tgt) * math.sqrt(self.ninp)\n","        tgt = self.pos_encoder_d(tgt)\n","\n","\n","        output = self.transformer(src.transpose(0,1), tgt.transpose(0,1), srcmask, tgtmask, src_key_padding_mask=srcpadmask, tgt_key_padding_mask=tgtpadmask)\n","        output = self.linear(output)\n","        return output\n","\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, dropout=0.1, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0).transpose(0, 1)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        x = x + self.pe[:x.size(0), :]\n","        return self.dropout(x)\n","\n","def gen_attention_mask(x):\n","    mask = torch.eq(x, 0)\n","    return mask"],"metadata":{"id":"Xqv018JjFxNJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wMsm4Xv2EHbq"},"outputs":[],"source":["def preprocess_sentence(sentence):\n","    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", str(sentence))\n","    sentence = sentence.strip()\n","    return sentence\n","\n","def evaluate(model, sentence):\n","    sentence = preprocess_sentence(sentence)\n","    input = torch.tensor([START_TOKEN + vocab.encode_as_ids(sentence) + END_TOKEN]).to(device)\n","    output = torch.tensor([START_TOKEN]).to(device)\n","\n","    # 디코더의 예측 시작\n","    model.eval()\n","    for i in range(MAX_LENGTH):\n","        src_mask = model.generate_square_subsequent_mask(input.shape[1]).to(device)\n","        tgt_mask = model.generate_square_subsequent_mask(output.shape[1]).to(device)\n","\n","        src_padding_mask = gen_attention_mask(input).to(device)\n","        tgt_padding_mask = gen_attention_mask(output).to(device)\n","\n","        predictions = model(input, output, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask).transpose(0,1)\n","        # 현재(마지막) 시점의 예측 단어를 받아온다.\n","        predictions = predictions[:, -1:, :]\n","        predicted_id = torch.LongTensor(torch.argmax(predictions.cpu(), axis=-1))\n","\n","\n","        # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n","        if torch.equal(predicted_id[0][0], torch.tensor(END_TOKEN[0])):\n","            break\n","\n","        # 마지막 시점의 예측 단어를 출력에 연결한다.\n","        # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n","        output = torch.cat([output, predicted_id.to(device)], axis=1)\n","\n","    return torch.squeeze(output, axis=0).cpu().numpy()\n","\n","def predict(model, sentence):\n","    prediction = evaluate(model, sentence)\n","    predicted_sentence = vocab.Decode(list(map(int,[i for i in prediction if i < vocab_size+7])))\n","\n","    print('Input: {}'.format(sentence))\n","    print('Output: {}'.format(predicted_sentence))\n","\n","    return predicted_sentence"]},{"cell_type":"code","source":["model = TFModel(vocab_size+7, 256, 8, 512, 3, 0.1).to(device)\n","model.load_state_dict(torch.load(\"chatbot_best.pth\", map_location=torch.device('cpu')))\n","predict(model, \"자소서 쓰기 너무 귀찮아 ㅠㅜ\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":146},"id":"YnJX0muDEMiP","executionInfo":{"status":"ok","timestamp":1689841060612,"user_tz":-540,"elapsed":883,"user":{"displayName":"Blessian White","userId":"18309571065164793243"}},"outputId":"10bcfa94-2bee-43c7-9be2-b36a0b842ce5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched src_key_padding_mask and mask is deprecated. Use same type for both instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Input: 자소서 쓰기 너무 귀찮아 ㅠㅜ\n","Output: 맞아 , 그래서 , 그래서 요즘은 요즘은 요즘은 사람들이 정말 많이 하는 것 같아\n"]},{"output_type":"execute_result","data":{"text/plain":["'맞아 , 그래서 , 그래서 요즘은 요즘은 요즘은 사람들이 정말 많이 하는 것 같아'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":36}]},{"cell_type":"markdown","source":["---\n","---"],"metadata":{"id":"YLjvyZkDPNu2"}},{"cell_type":"markdown","source":["# Class"],"metadata":{"id":"iAccA2htfb7o"}},{"cell_type":"markdown","source":["## 필요사항\n","\n","- all.txt\n","- chatbot.model\n","- chatbot.vocab\n","- chatbot_best.pth"],"metadata":{"id":"TnypoiqqYuxu"}},{"cell_type":"markdown","source":["## Import"],"metadata":{"id":"_QfGu-XbffuX"}},{"cell_type":"code","source":["import re\n","import math\n","import torch\n","import sentencepiece as spm\n","from pathlib import Path\n","from torch import nn\n","from torch.nn import Transformer"],"metadata":{"id":"qJQzLTmDZlng","executionInfo":{"status":"ok","timestamp":1689842061979,"user_tz":-540,"elapsed":2162,"user":{"displayName":"Blessian White","userId":"18309571065164793243"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"Nf8CavAyfhx3"}},{"cell_type":"code","source":["class TFModel(nn.Module):\n","    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n","        super(TFModel, self).__init__()\n","        self.transformer = Transformer(ninp, nhead, dim_feedforward=nhid, num_encoder_layers=nlayers, num_decoder_layers=nlayers,dropout=dropout)\n","        self.pos_encoder = PositionalEncoding(ninp, dropout)\n","        self.encoder = nn.Embedding(ntoken, ninp)\n","\n","        self.pos_encoder_d = PositionalEncoding(ninp, dropout)\n","        self.encoder_d = nn.Embedding(ntoken, ninp)\n","\n","        self.ninp = ninp\n","        self.ntoken = ntoken\n","\n","        self.linear = nn.Linear(ninp, ntoken)\n","        self.init_weights()\n","\n","    def generate_square_subsequent_mask(self, sz):\n","        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n","        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","        return mask\n","\n","    def init_weights(self):\n","        initrange = 0.1\n","        self.encoder.weight.data.uniform_(-initrange, initrange)\n","\n","    def forward(self, src, tgt, srcmask, tgtmask, srcpadmask, tgtpadmask):\n","        src = self.encoder(src) * math.sqrt(self.ninp)\n","        src = self.pos_encoder(src)\n","\n","        tgt = self.encoder_d(tgt) * math.sqrt(self.ninp)\n","        tgt = self.pos_encoder_d(tgt)\n","\n","\n","        output = self.transformer(src.transpose(0,1), tgt.transpose(0,1), srcmask, tgtmask, src_key_padding_mask=srcpadmask, tgt_key_padding_mask=tgtpadmask)\n","        output = self.linear(output)\n","        return output\n","\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, dropout=0.1, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0).transpose(0, 1)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        x = x + self.pe[:x.size(0), :]\n","        return self.dropout(x)\n","\n","def gen_attention_mask(x):\n","    mask = torch.eq(x, 0)\n","    return mask"],"metadata":{"id":"UOAoqH8aTTvO","executionInfo":{"status":"ok","timestamp":1689842061980,"user_tz":-540,"elapsed":5,"user":{"displayName":"Blessian White","userId":"18309571065164793243"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Chatbot"],"metadata":{"id":"N-hgpuTBfjt4"}},{"cell_type":"code","source":["class Chatbot():\n","    def __init__(self):\n","        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","        self.vocab_size = 30000\n","        self.set_spm()\n","        self.set_vocabulary()\n","        self.set_model(self.vocab_size)\n","        print(\"Model Loaded!\")\n","\n","    def set_vocabulary(self):\n","        path = next(Path(\"./\").glob(\"**/chatbot.model\"))\n","        vocab = spm.SentencePieceProcessor()\n","        vocab.load(str(path))\n","        self.vocab = vocab\n","\n","    def set_spm(self):\n","        corpus = str(next(Path(\"./\").glob(\"**/all.txt\")))\n","        prefix = \"chatbot\"\n","        vocab_size = 30000\n","        spm.SentencePieceTrainer.train(\n","            f\"--input={corpus} --model_prefix={prefix} --vocab_size={vocab_size + 7}\" +\n","            \" --model_type=bpe\" +\n","            \" --max_sentence_length=999999\" + # 문장 최대 길이\n","            \" --pad_id=0 --pad_piece=[PAD]\" + # pad (0)\n","            \" --unk_id=1 --unk_piece=[UNK]\" + # unknown (1)\n","            \" --bos_id=2 --bos_piece=[BOS]\" + # begin of sequence (2)\n","            \" --eos_id=3 --eos_piece=[EOS]\" + # end of sequence (3)\n","            \" --user_defined_symbols=[SEP],[CLS],[MASK]\") # 사용자 정의 토큰\n","        self.spm = spm\n","\n","    def set_model(self, vocab_size):\n","        path = next(Path(\"./\").glob(\"**/chatbot_best.pth\"))\n","        model = TFModel(vocab_size+7, 256, 8, 512, 3, 0.1).to(self.device)\n","        model.load_state_dict(torch.load(str(path), map_location=torch.device('cpu')))\n","        self.model = model\n","\n","    @staticmethod\n","    def preprocess_sentence(sentence):\n","        sentence = re.sub(r\"([?.!,])\", r\" \\1 \", str(sentence))\n","        sentence = sentence.strip()\n","        return sentence\n","\n","    def evaluate(self, model, sentence):\n","        MAX_LENGTH = 40\n","        START_TOKEN = [2]\n","        END_TOKEN = [3]\n","\n","        sentence = self.preprocess_sentence(sentence)\n","        input = torch.tensor([START_TOKEN + self.vocab.encode_as_ids(sentence) + END_TOKEN]).to(self.device)\n","        output = torch.tensor([START_TOKEN]).to(self.device)\n","\n","        def gen_attention_mask(x):\n","            mask = torch.eq(x, 0)\n","            return mask\n","\n","        # 디코더의 예측 시작\n","        model.eval()\n","        for i in range(MAX_LENGTH):\n","            src_mask = model.generate_square_subsequent_mask(input.shape[1]).to(self.device)\n","            tgt_mask = model.generate_square_subsequent_mask(output.shape[1]).to(self.device)\n","\n","            src_padding_mask = gen_attention_mask(input).to(self.device)\n","            tgt_padding_mask = gen_attention_mask(output).to(self.device)\n","\n","            predictions = model(input, output, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask).transpose(0,1)\n","            # 현재(마지막) 시점의 예측 단어를 받아온다.\n","            predictions = predictions[:, -1:, :]\n","            predicted_id = torch.LongTensor(torch.argmax(predictions.cpu(), axis=-1))\n","\n","\n","            # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n","            if torch.equal(predicted_id[0][0], torch.tensor(END_TOKEN[0])):\n","                break\n","\n","            # 마지막 시점의 예측 단어를 출력에 연결한다.\n","            # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n","            output = torch.cat([output, predicted_id.to(self.device)], axis=1)\n","\n","        return torch.squeeze(output, axis=0).cpu().numpy()\n","\n","    def predict(self, sentence):\n","        prediction = self.evaluate(self.model, sentence)\n","        predicted_sentence = self.vocab.Decode(list(map(int,[i for i in prediction if i < self.vocab_size+7])))\n","\n","        print('Input: {}'.format(sentence))\n","        print('Output: {}'.format(predicted_sentence))\n","\n","        return predicted_sentence"],"metadata":{"id":"31_7it0JPOIe","executionInfo":{"status":"ok","timestamp":1689842239591,"user_tz":-540,"elapsed":751,"user":{"displayName":"Blessian White","userId":"18309571065164793243"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pfvdfxWOP_Bl","executionInfo":{"status":"ok","timestamp":1689842239591,"user_tz":-540,"elapsed":2,"user":{"displayName":"Blessian White","userId":"18309571065164793243"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["a = Chatbot()"],"metadata":{"id":"zDKa_JPuSPNG","executionInfo":{"status":"ok","timestamp":1689842296786,"user_tz":-540,"elapsed":56878,"user":{"displayName":"Blessian White","userId":"18309571065164793243"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["a.predict(\"자소서 쓰기 너무 귀찮아 ㅠㅜ\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":146},"id":"ZQ_uCW0aSRRL","executionInfo":{"status":"ok","timestamp":1689842297074,"user_tz":-540,"elapsed":297,"user":{"displayName":"Blessian White","userId":"18309571065164793243"}},"outputId":"4b694e64-aee6-42fb-9555-96f7edac0b86"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched src_key_padding_mask and mask is deprecated. Use same type for both instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Input: 자소서 쓰기 너무 귀찮아 ㅠㅜ\n","Output: 맞아 , 그래서 , 그래서 요즘은 요즘은 요즘은 사람들이 정말 많이 하는 것 같아\n"]},{"output_type":"execute_result","data":{"text/plain":["'맞아 , 그래서 , 그래서 요즘은 요즘은 요즘은 사람들이 정말 많이 하는 것 같아'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":[],"metadata":{"id":"_sG5ad6nSdTo"},"execution_count":null,"outputs":[]}]}